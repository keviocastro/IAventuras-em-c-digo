{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ef84437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\pedro\\miniconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\pedro\\miniconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\pedro\\miniconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\pedro\\miniconda3\\lib\\site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pedro\\miniconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pedro\\miniconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\pedro\\miniconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\pedro\\miniconda3\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\pedro\\miniconda3\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pedro\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas scikit-learn joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cd6403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data mais recente no dataset de check-ins: 2023-10-15 00:00:00\n",
      "Acurácia no conjunto de teste: 0.712\n",
      "Relatório de classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.86      0.78       605\n",
      "           1       0.69      0.49      0.57       395\n",
      "\n",
      "    accuracy                           0.71      1000\n",
      "   macro avg       0.71      0.67      0.68      1000\n",
      "weighted avg       0.71      0.71      0.70      1000\n",
      "\n",
      "Modelo de churn salvo como churn_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from datetime import timedelta\n",
    "import joblib\n",
    "\n",
    "alunos_df = pd.read_csv(\"df_alunos_novo.csv\", sep=\",\")  \n",
    "checkins_df = pd.read_csv(\"df_checkins2.csv\", sep=\";\")  \n",
    "\n",
    "# Converte a coluna de datas para datetime\n",
    "checkins_df[\"data\"] = pd.to_datetime(checkins_df[\"data\"], format=\"%d/%m/%Y\")\n",
    "\n",
    "# Encontra a data mais recente no dataset de checkins (necessário para calcular quanto tempo desde o ultimo checkin pois dataset usado para treino é antigo)\n",
    "data_mais_recente = checkins_df[\"data\"].max()\n",
    "print(\"Data mais recente no dataset de check-ins:\", data_mais_recente)\n",
    "\n",
    "alunos_train, alunos_test = train_test_split(alunos_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Função para calcular as features\n",
    "def calcular_features_from_csv(alunos_df, checkins_df, data_referencia):\n",
    "    \"\"\"Calcula as features para o modelo de churn usando dados dos CSVs.\"\"\"\n",
    "    data = []\n",
    "\n",
    "    checkins_dict = {}\n",
    "    for _, checkin in checkins_df.iterrows():\n",
    "        if checkin[\"aluno_id\"] not in checkins_dict:\n",
    "            checkins_dict[checkin[\"aluno_id\"]] = []\n",
    "        checkins_dict[checkin[\"aluno_id\"]].append(checkin)\n",
    "\n",
    "    for _, aluno in alunos_df.iterrows():\n",
    "        # Checkins do aluno\n",
    "        checkins_aluno = checkins_dict.get(aluno[\"id\"], [])\n",
    "\n",
    "        # Frequência semanal\n",
    "        frequencia_semanal = sum(\n",
    "            1 for checkin in checkins_aluno\n",
    "            if checkin[\"data\"] >= data_referencia - timedelta(days=7)\n",
    "        )\n",
    "\n",
    "        # Tempo desde o último checkin\n",
    "        ultimo_checkin = max(\n",
    "            (checkin[\"data\"] for checkin in checkins_aluno),\n",
    "            default=None\n",
    "        )\n",
    "        tempo_ultimo_checkin = (data_referencia - ultimo_checkin).days if ultimo_checkin else 30\n",
    "\n",
    "        # Duração média das visitas\n",
    "        duracoes = [\n",
    "            (pd.to_datetime(checkin[\"horario_checkout\"]).hour * 60 + pd.to_datetime(checkin[\"horario_checkout\"]).minute) -\n",
    "            (pd.to_datetime(checkin[\"horario_checkin\"]).hour * 60 + pd.to_datetime(checkin[\"horario_checkin\"]).minute)\n",
    "            for checkin in checkins_aluno\n",
    "            if not pd.isnull(checkin[\"horario_checkin\"]) and not pd.isnull(checkin[\"horario_checkout\"])\n",
    "        ]\n",
    "        duracao_media_visitas = sum(duracoes) / len(duracoes) if duracoes else 0\n",
    "\n",
    "        # Tipo de plano\n",
    "        PLANO_MAP = {\"Basic\": 1, \"Student\": 2, \"Pro\": 3}\n",
    "        tipo_plano = PLANO_MAP.get(aluno[\"plano\"], -1)  # Retorna -1 se o plano não estiver no mapeamento\n",
    "\n",
    "        data.append([frequencia_semanal, tempo_ultimo_checkin, duracao_media_visitas, tipo_plano])\n",
    "\n",
    "    return data\n",
    "\n",
    "features_train = calcular_features_from_csv(alunos_train, checkins_df, data_mais_recente)\n",
    "features_test = calcular_features_from_csv(alunos_test, checkins_df, data_mais_recente)\n",
    "\n",
    "labels_train = alunos_train[\"risco_churn\"].tolist()\n",
    "labels_test = alunos_test[\"risco_churn\"].tolist()\n",
    "\n",
    "df_train = pd.DataFrame(features_train, columns=['frequencia_semanal', 'tempo_ultimo_checkin', 'duracao_media_visitas', 'tipo_plano'])\n",
    "df_test = pd.DataFrame(features_test, columns=['frequencia_semanal', 'tempo_ultimo_checkin', 'duracao_media_visitas', 'tipo_plano'])\n",
    "\n",
    "X_train = df_train\n",
    "y_train = labels_train\n",
    "X_test = df_test\n",
    "y_test = labels_test\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,       \n",
    "    max_depth=10,           \n",
    "    min_samples_leaf=5,    \n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Acurácia no conjunto de teste:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Relatório de classificação:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "joblib.dump(model, \"churn_model.pkl\")\n",
    "print(\"Modelo de churn salvo como churn_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
